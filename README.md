# Tumor Detection in Routine Breast Mammograms
To detect the presence of tumors in routine breast mammograms we use eight classification algorithms that each label the data as 1.0, tumor present, or 0.0, tumor absent. We then compare these predictions with the true classifications to generate performance metrics.  The eight algorithms are:  Gaussian Naïve Bayes, Random Forest Classifier, Naïve Bayes, K-Nearest Neighbor, K-Nearest Neighbor Modified, Decision Trees Classifier, Support Vector Machines, and a randombase case. The dataset we use comes in two parts: a feature space, encoded in a text file where each row rep-resents a feature vector for one of 322 mammogram images, and a classification file, where each row carries a single binary tumor vs. no-tumor value. The feature space for each mammogram consists of a six dimensional vector of floats. The floats are generated by running the original image set through a Matlab computer vision toolkit that, for each image, generates a histogram of oriented gradients (HOG) and returns a set of defining features in the form of 6 float values.  It is best to think of this HOG method and accompanying 6 dimensional vector as the plotting of a  point in space. We should thus expect images containing tumors to cluster in one region of space, and images not containing tumors to cluster into another. We split the dataset into training and test sets, using 230 of the 322 for training purposes. The training set consists of an array of feature vectors with accompanying classifications (the binary 0.0 or 1.0 value for tumor vs. no-tumor), and the test set consists only of the feature vectors, f. Following training, we use each algorithm to generate predictions on the test set.
<br/>

## Running the system:
The system can be broken down into three components: <br>
1. Data files:
  * fullData.txt contains the complete dataset
  * simpleData.txt contains data filtered for only binary 0.0 or 1.0 classification
  * features.txt contains feature vectors for each of the entries
2. Algorithm files:
  * base.py (random base case), decisionTrees.py, gaussianNaiveBayes.py, knn\_modified.py, knn.py, naiveBayes.py, randomForest.py, supportVector.py
3. Main testing files:
  * classifier.py
  * tuning.py

Each of the algorithm files contains its respective prototype classification function. Via python's import operator, these are loaded into the main testing file, classifier.py, which then passes the data set as well as any additional arguments to each of the classifiers via python's dot notation (ex: decisionTrees.decisionTreeFunction()). To receive the results (in the form of a matplotlib print out), simply run *python classifier.py* in terminal. For examples of tuning, you can likewise run *python tuning.py*; this will output graphs used during the process of tuning parameters for each classifier.

## Data:
 http://peipa.essex.ac.uk/pix/mias/
